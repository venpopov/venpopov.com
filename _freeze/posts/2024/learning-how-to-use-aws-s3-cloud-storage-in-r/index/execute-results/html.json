{
  "hash": "0da65cddf30193fbfe3bee34a463f874",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Learning how to use AWS S3 cloud storage in R\"\nsubtitle: \"\"\ncategories: [Reproducibility,  R,  Cloud Storage,  Workflow,  2024]\ndate: \"2024-11-17\"\ndraft: true\nexecute: \n  error: true\n---\n\n\n\nOk, it’s time I learn this. I hope it can simplify my reproducible research workflows, particularly when using targets and versioning data objects. I’m going to start with the basics and then see how I can integrate it into my workflow.\n\n## An overview of necessary steps:\n\n-   [x] Install a useful R package called [aws.s3](https://github.com/cloudyr/aws.s3)\n-   [x] Set up an [AWS account](https://aws.amazon.com/s3/)\n-   [x] Create a new user in the AWS Identity and Access Management (IAM) console\n-   [x] Generate keypair in the IAM management console\n-   [x] Specify a set of environment variables in .Renviron\n\n## Setup\n\n### Install `aws.s3`\n\n``` r\ninstall.packages('aws.s3')\n```\n\n### Setup AWS account\n\nGo to <https://aws.amazon.com/s3/> and follow the process\n\n### Create a new user in the AWS Identity and Access Management (IAM) console\n\nCreate a new user that only has access to S3. Go to the [IAM console](https://us-east-1.console.aws.amazon.com/iam/home?region=eu-north-1#/users) and create a new user. What should the username be? My root user is `venpopov`, but is that the user name, or is it `root`? I'll try to make `venpopov_s3` as the new user.\n\n![](images/paste-1.png)\n\nI get a prompt to add the user to a group. Should I make a group for S3 access only? Let's try that. It might make it easier down the line if I have other users to add\n\n![](images/paste-4.png)\n\n![](images/paste-5.png)\n\n### Create access key\n\nGo to **Users \\> Username \\> Create access key**\n\nThe key will not be saved anywhere on AWS, so better save it somewhere safe (in my case, an encrypted note)\n\n### Specify a set of environment variables in .Renviron\n\n``` bash\nAWS_ACCESS_KEY_ID=YOUR_ACCESS_KEY\nAWS_SECRET_ACCESS_KEY=YOUR_SECRET_ACCESS_KEY\nAWS_DEFAULT_REGION=REGION\n```\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in readRenviron(\".env\"): file '.env' cannot be opened for reading\n```\n\n\n:::\n:::\n\n\n\n## Working with `aws.s3`\n\nLoad the package and check available buckets on the account. Initial results are of course 0:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"aws.s3\")\nbucketlist()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndata frame with 0 columns and 0 rows\n```\n\n\n:::\n:::\n\n\n\nLet's create a new bucket first:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nput_bucket(\"learning-aws\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 4\n $ Code     : chr \"AccessDenied\"\n $ Message  : chr \"User: Anonymous is not authorized to perform: s3:CreateBucket on resource: \\\"arn:aws:s3:::learning-aws\\\" becaus\"| __truncated__\n $ RequestId: chr \"PRBR3B8FD380TYVK\"\n $ HostId   : chr \"1yGsvpjhRtKQId+ez7P8p+Y80kCOJ+RLBJ9efRM3Nru6eO/6W0Tkj1cYjbeMWWFKNJe4UTmhoKY=\"\n - attr(*, \"headers\")=List of 7\n  ..$ x-amz-request-id : chr \"PRBR3B8FD380TYVK\"\n  ..$ x-amz-id-2       : chr \"1yGsvpjhRtKQId+ez7P8p+Y80kCOJ+RLBJ9efRM3Nru6eO/6W0Tkj1cYjbeMWWFKNJe4UTmhoKY=\"\n  ..$ content-type     : chr \"application/xml\"\n  ..$ transfer-encoding: chr \"chunked\"\n  ..$ date             : chr \"Sun, 12 Jan 2025 13:33:55 GMT\"\n  ..$ connection       : chr \"close\"\n  ..$ server           : chr \"AmazonS3\"\n  ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n - attr(*, \"class\")= chr \"aws_error\"\nNULL\n```\n\n\n:::\n\n::: {.cell-output .cell-output-error}\n\n```\nError in parse_aws_s3_response(r, Sig, verbose = verbose): Forbidden (HTTP 403).\n```\n\n\n:::\n:::\n\n\n\nInteresting, the bucket names are not unique to users - this one is already taken. Well, let's use this opportunity to try reading from a bucket instead. I wonder what this one holds:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_bucket(\"learning-aws\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 4\n $ Code     : chr \"AccessDenied\"\n $ Message  : chr \"Access Denied\"\n $ RequestId: chr \"XKQ5JG5KX4CN0KJB\"\n $ HostId   : chr \"Ou5nza9/PM9tEQLID1VGuOkT4McQl/dF7+Z05T6E3V+RPkq18p6Blj90IYGTynIY8YZ4i9044kA=\"\n - attr(*, \"headers\")=List of 7\n  ..$ x-amz-bucket-region: chr \"us-east-1\"\n  ..$ x-amz-request-id   : chr \"XKQ5JG5KX4CN0KJB\"\n  ..$ x-amz-id-2         : chr \"Ou5nza9/PM9tEQLID1VGuOkT4McQl/dF7+Z05T6E3V+RPkq18p6Blj90IYGTynIY8YZ4i9044kA=\"\n  ..$ content-type       : chr \"application/xml\"\n  ..$ transfer-encoding  : chr \"chunked\"\n  ..$ date               : chr \"Sun, 12 Jan 2025 13:33:56 GMT\"\n  ..$ server             : chr \"AmazonS3\"\n  ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n - attr(*, \"class\")= chr \"aws_error\"\nNULL\n```\n\n\n:::\n\n::: {.cell-output .cell-output-error}\n\n```\nError in parse_aws_s3_response(r, Sig, verbose = verbose): Forbidden (HTTP 403).\n```\n\n\n:::\n:::\n\n\n\nError. Hmm, some [googling](https://stackoverflow.com/questions/25027462/aws-s3-the-bucket-you-are-attempting-to-access-must-be-addressed-using-the-spec) reveals that this is somehow related to the region, which I set by default in my case to \"eu-central-1\". How to resolve this? Turns out I should specify the region manually when using `get_bucket`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_bucket(\"learning-aws\", region = \"us-east-1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 4\n $ Code     : chr \"AccessDenied\"\n $ Message  : chr \"Access Denied\"\n $ RequestId: chr \"XKQ84FPCTG9A4QMS\"\n $ HostId   : chr \"8Zt624b+qLh+ogJO5WM54Iy99Sp3pyh1TUZwzLghvjLWVQQolQXtz8hGwHCbcU5VCfukboYzM20=\"\n - attr(*, \"headers\")=List of 7\n  ..$ x-amz-bucket-region: chr \"us-east-1\"\n  ..$ x-amz-request-id   : chr \"XKQ84FPCTG9A4QMS\"\n  ..$ x-amz-id-2         : chr \"8Zt624b+qLh+ogJO5WM54Iy99Sp3pyh1TUZwzLghvjLWVQQolQXtz8hGwHCbcU5VCfukboYzM20=\"\n  ..$ content-type       : chr \"application/xml\"\n  ..$ transfer-encoding  : chr \"chunked\"\n  ..$ date               : chr \"Sun, 12 Jan 2025 13:33:56 GMT\"\n  ..$ server             : chr \"AmazonS3\"\n  ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n - attr(*, \"class\")= chr \"aws_error\"\nNULL\n```\n\n\n:::\n\n::: {.cell-output .cell-output-error}\n\n```\nError in parse_aws_s3_response(r, Sig, verbose = verbose): Forbidden (HTTP 403).\n```\n\n\n:::\n:::\n\n\n\nAlright, this isn't a public bucket... Let's try it with a dataset I [found online](https://aws.amazon.com/marketplace/pp/prodview-qh4qqd6ebnqio?sr=0-100&applicationId=AWSMPContessa#resources), which is an archive of Full-text journal articles from PubMed. I also switch to the `get_bucket_df()` function so that I get a data.frame for easier use:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npmc_bucket <- get_bucket_df(\n  bucket = 'pmc-oa-opendata', \n  region = \"us-east-1\",\n  max = 1000)\nhead(pmc_bucket)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                        Key             LastModified\n1                        author_manuscript/ 2021-06-17T18:22:13.000Z\n2                    author_manuscript/txt/ 2021-06-17T18:23:29.000Z\n3 author_manuscript/txt/all/PMC10000016.txt 2024-06-16T09:20:24.000Z\n4 author_manuscript/txt/all/PMC10000018.txt 2024-06-16T09:20:13.000Z\n5 author_manuscript/txt/all/PMC10000019.txt 2024-06-16T09:20:16.000Z\n6 author_manuscript/txt/all/PMC10000020.txt 2024-06-16T09:20:42.000Z\n                                ETag  Size\n1 \"d41d8cd98f00b204e9800998ecf8427e\"     0\n2 \"d41d8cd98f00b204e9800998ecf8427e\"     0\n3 \"b64f69f96fa82f24914dc59b0f60b385\" 23432\n4 \"7eaa9c853b05ba20c3eff8bd0cd1fea9\" 14691\n5 \"be821355607ee4228a82e10a2a31f77b\" 12272\n6 \"ebdb75e4cba9bbd7b6e18c44ee76b15c\" 90950\n                                                          Owner_ID\n1 7dd4dcfe9b004fb7433c61af3e87972f2e9477fa7f0760a02827f771b41b3455\n2 7dd4dcfe9b004fb7433c61af3e87972f2e9477fa7f0760a02827f771b41b3455\n3 7dd4dcfe9b004fb7433c61af3e87972f2e9477fa7f0760a02827f771b41b3455\n4 7dd4dcfe9b004fb7433c61af3e87972f2e9477fa7f0760a02827f771b41b3455\n5 7dd4dcfe9b004fb7433c61af3e87972f2e9477fa7f0760a02827f771b41b3455\n6 7dd4dcfe9b004fb7433c61af3e87972f2e9477fa7f0760a02827f771b41b3455\n          Owner_DisplayName StorageClass          Bucket\n1 NIH_NLM_NCBI_SRA_opendata     STANDARD pmc-oa-opendata\n2 NIH_NLM_NCBI_SRA_opendata     STANDARD pmc-oa-opendata\n3 NIH_NLM_NCBI_SRA_opendata     STANDARD pmc-oa-opendata\n4 NIH_NLM_NCBI_SRA_opendata     STANDARD pmc-oa-opendata\n5 NIH_NLM_NCBI_SRA_opendata     STANDARD pmc-oa-opendata\n6 NIH_NLM_NCBI_SRA_opendata     STANDARD pmc-oa-opendata\n```\n\n\n:::\n:::\n\n\n\nWe see a list of articles available as .txt files. Let's download one of them:\n\n## A surprise - need to use a different package\n\nAt this point I notice that the package [hasn't received any updates since 2018](https://github.com/cloudyr/aws.s3/issues/433), so I'll ignore this method. Some functions still seem to work, but who knows for how long, and it's never a good idea to base a workflow on a library that's not maintained.\n\nAn alternative seems to be the [paws](https://github.com/paws-r/paws) package, which is featured on [AWS blog](https://aws.amazon.com/blogs/opensource/getting-started-with-r-on-amazon-web-services/). Another option is the [s3fs](https://github.com/DyfanJones/s3fs) package which let's you treat the S3 service as a file system. I'll focus now on 'paws', since it underlies s3fs, but might come back later to the other package.\n\nInstall the package of course:\n\n``` r\ninstall.packages('paws')\n```\n\nLoad the package and create a new bucket for testing\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(paws)\n```\n:::\n\n\n\nWe start by creating what paws calls a 'client' for the S3 service. Since I've already set up the credentials, it works very simply:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmys3 <- s3()\n```\n:::\n\n\n\nThis is a simple list of functions which we can called with `mys3$functionname()` syntax. Here are all available functions:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(mys3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  [1] \"abort_multipart_upload\"                         \n  [2] \"complete_multipart_upload\"                      \n  [3] \"copy_object\"                                    \n  [4] \"create_bucket\"                                  \n  [5] \"create_multipart_upload\"                        \n  [6] \"create_session\"                                 \n  [7] \"delete_bucket\"                                  \n  [8] \"delete_bucket_analytics_configuration\"          \n  [9] \"delete_bucket_cors\"                             \n [10] \"delete_bucket_encryption\"                       \n [11] \"delete_bucket_intelligent_tiering_configuration\"\n [12] \"delete_bucket_inventory_configuration\"          \n [13] \"delete_bucket_lifecycle\"                        \n [14] \"delete_bucket_metrics_configuration\"            \n [15] \"delete_bucket_ownership_controls\"               \n [16] \"delete_bucket_policy\"                           \n [17] \"delete_bucket_replication\"                      \n [18] \"delete_bucket_tagging\"                          \n [19] \"delete_bucket_website\"                          \n [20] \"delete_object\"                                  \n [21] \"delete_object_tagging\"                          \n [22] \"delete_objects\"                                 \n [23] \"delete_public_access_block\"                     \n [24] \"get_bucket_accelerate_configuration\"            \n [25] \"get_bucket_acl\"                                 \n [26] \"get_bucket_analytics_configuration\"             \n [27] \"get_bucket_cors\"                                \n [28] \"get_bucket_encryption\"                          \n [29] \"get_bucket_intelligent_tiering_configuration\"   \n [30] \"get_bucket_inventory_configuration\"             \n [31] \"get_bucket_lifecycle\"                           \n [32] \"get_bucket_lifecycle_configuration\"             \n [33] \"get_bucket_location\"                            \n [34] \"get_bucket_logging\"                             \n [35] \"get_bucket_metrics_configuration\"               \n [36] \"get_bucket_notification\"                        \n [37] \"get_bucket_notification_configuration\"          \n [38] \"get_bucket_ownership_controls\"                  \n [39] \"get_bucket_policy\"                              \n [40] \"get_bucket_policy_status\"                       \n [41] \"get_bucket_replication\"                         \n [42] \"get_bucket_request_payment\"                     \n [43] \"get_bucket_tagging\"                             \n [44] \"get_bucket_versioning\"                          \n [45] \"get_bucket_website\"                             \n [46] \"get_object\"                                     \n [47] \"get_object_acl\"                                 \n [48] \"get_object_attributes\"                          \n [49] \"get_object_legal_hold\"                          \n [50] \"get_object_lock_configuration\"                  \n [51] \"get_object_retention\"                           \n [52] \"get_object_tagging\"                             \n [53] \"get_object_torrent\"                             \n [54] \"get_public_access_block\"                        \n [55] \"head_bucket\"                                    \n [56] \"head_object\"                                    \n [57] \"list_bucket_analytics_configurations\"           \n [58] \"list_bucket_intelligent_tiering_configurations\" \n [59] \"list_bucket_inventory_configurations\"           \n [60] \"list_bucket_metrics_configurations\"             \n [61] \"list_buckets\"                                   \n [62] \"list_directory_buckets\"                         \n [63] \"list_multipart_uploads\"                         \n [64] \"list_object_versions\"                           \n [65] \"list_objects\"                                   \n [66] \"list_objects_v2\"                                \n [67] \"list_parts\"                                     \n [68] \"put_bucket_accelerate_configuration\"            \n [69] \"put_bucket_acl\"                                 \n [70] \"put_bucket_analytics_configuration\"             \n [71] \"put_bucket_cors\"                                \n [72] \"put_bucket_encryption\"                          \n [73] \"put_bucket_intelligent_tiering_configuration\"   \n [74] \"put_bucket_inventory_configuration\"             \n [75] \"put_bucket_lifecycle\"                           \n [76] \"put_bucket_lifecycle_configuration\"             \n [77] \"put_bucket_logging\"                             \n [78] \"put_bucket_metrics_configuration\"               \n [79] \"put_bucket_notification\"                        \n [80] \"put_bucket_notification_configuration\"          \n [81] \"put_bucket_ownership_controls\"                  \n [82] \"put_bucket_policy\"                              \n [83] \"put_bucket_replication\"                         \n [84] \"put_bucket_request_payment\"                     \n [85] \"put_bucket_tagging\"                             \n [86] \"put_bucket_versioning\"                          \n [87] \"put_bucket_website\"                             \n [88] \"put_object\"                                     \n [89] \"put_object_acl\"                                 \n [90] \"put_object_legal_hold\"                          \n [91] \"put_object_lock_configuration\"                  \n [92] \"put_object_retention\"                           \n [93] \"put_object_tagging\"                             \n [94] \"put_public_access_block\"                        \n [95] \"restore_object\"                                 \n [96] \"select_object_content\"                          \n [97] \"upload_part\"                                    \n [98] \"upload_part_copy\"                               \n [99] \"write_get_object_response\"                      \n[100] \"download_file\"                                  \n[101] \"generate_presigned_url\"                         \n[102] \".internal\"                                      \n```\n\n\n:::\n:::\n\n\n\nthe `create_bucket` function sounds like what we need\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmys3$create_bucket(\n  Bucket = \"learning-paws-aws-2024\",\n  CreateBucketConfiguration = list(\n    LocationConstraint = \"eu-central-1\"\n  )\n)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: No compatible credentials provided. Use `options(\"paws.log_level\" = 3L)` for more information.\n```\n\n\n:::\n:::\n\n\n\nWe can get a list of available buckets, which is currently 0:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmys3$list_buckets()\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: No compatible credentials provided. Use `options(\"paws.log_level\" = 3L)` for more information.\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}