{
  "hash": "8d7960114ebee35ad1f3b57394493078",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"R love you, R hate you\"\ncategories: [R,  programming,  2025]\ndate: \"2025-02-21\"\nexecute:\n  error: true\n  cache: false\nknitr:\n  opts_chunk: \n    collapse: true\n    comment: \"#>\"\n---\n\n::: {.cell}\n\n:::\n\n\n\nI do the majority of my coding in R. I've grown to love the language despite many of its quirks. Perhaps this is just Stockholm's Syndrom as I joked in my \"Intro to programming\" class recently, though I genuinely enjoy the language and its functional roots.\n\nThat said, there are things that are objectively bad about it, with default that no sane person would choose. The more time I spend writing code for packages rather than data analysis, the more I've grown annoyed at how much extra work you need to do to avoid perplexing bugs and behavior. This is partly a weakness of dynamically typed languages - rather than depending on type-checking built into the language, you need to program defensively and explicitly handle user-input and whether it is what you expect it to be (some good posts on the topic [here](https://blog.r-hub.io/2022/03/10/input-checking/#checking-function-inputs-using-r-packages) and [here](https://blog.djnavarro.net/posts/2023-08-08_being-assertive/#just-assertr-carr)). It's a problem important enough that it has lead to the proliferation of many packages that aim to assist you with it - e.g. [checkmate](https://mllg.github.io/checkmate/articles/checkmate.html), [ensurer](https://github.com/smbache/ensurer), [tester](https://github.com/gastonstat/tester), [assertive](https://cran.r-project.org/web/packages/assertive/index.html), [assertr](https://docs.ropensci.org/assertr/index.html)). But another part is just due to some genuinely weird choices built in many of R's base functions.\n\n### A case of bait and switch\n\nHere is a simple case which recently lead to a [headscratcher of a bug](https://github.com/venpopov/bmm/issues/269) in our [bmm package](../../2024/introducing-bmm). You write a function which does something different depending on a parameter:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngreeting <- function(name, language) {\n  if (language == \"chinese\") {\n    out <- paste0(\"嗨 \", name, \"! 多么美好的一天\")\n  } else if (language == \"german\") {\n    out <- paste0(\"Hallo \", name, \"! Was für ein toller Tag!\")\n  } else if (language == \"bulgarian\") {\n    out <- paste0(\"Здравей \", name, \"! Какъв страхотен ден!\")\n  }\n  cat(out, \"\\n\")\n}\n```\n:::\n\n\n\nSimple enough, right?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngreeting(\"Ven\", \"german\")\n#> Hallo Ven! Was für ein toller Tag!\n```\n:::\n\n\n\nYou get weird errors with non-character input if you don't properly check that the language argument is a character or that it is a valid choice, but at least the user will get an error:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngreeting(\"Ven\", 2)\n#> Error in greeting(\"Ven\", 2): object 'out' not found\ngreeting(\"Ven\", \"japanese\")\n#> Error in greeting(\"Ven\", \"japanese\"): object 'out' not found\n```\n:::\n\n\n\nOk, maybe a little confusing for the user (\"object 'out'? What is object 'out'?\"), but fine. You can and should go the extra mile and validate the input, but let's keep going. Now, if you had many different language options, you might decide to use a `switch` statement instead of an if/else structure:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngreeting2 <- function(name, language) {\n  out <- switch(language,\n    chinese = paste0(\"嗨 \", name, \"! 多么美好的一天\"),\n    german = paste0(\"Hallo \", name, \"! Was für ein toller Tag!\"),\n    bulgarian = paste0(\"Здравей \", name, \"! Какъв страхотен ден!\")\n  )\n  cat(out, \"\\n\")\n}\n```\n:::\n\n\n\nOur `switch` handles 3 defined cases, just like the if/else version, so unless you read the documentation, or have been already burnt by this, you might expect that this should fail:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngreeting2(\"Ven\", 2)\n#> Hallo Ven! Was für ein toller Tag!\n```\n:::\n\n\n\nOh, it runs! Ok, so even though we have explicitly defined the cases by name, switch tries to be clever and interpret integer input as a case selection. Not only that, but it will try really hard to make the input an integer if it can. The following makes no sense as a language selector, but R happily forces 2.8 into an integer sleeve and greets us again:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngreeting2(\"Ven\", 2.8)\n#> Hallo Ven! Was für ein toller Tag!\n```\n:::\n\n\n\nFine, it's strange, but who in their right mind will try to pass numeric values for a language variable? Maybe no one on purpose, but some things in R are (sometimes) secretly integers. Namely, factors. Consider this - we have some `data.frame` with names and language preferences of users, the latter of which is coded as a factor variable.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nusers <- data.frame(\n  name = c(\"Ven\", \"Gidon\", \"Chenyu\"),\n  language = factor(c(\"bulgarian\", \"german\", \"chinese\"))\n)\n\nusers\n#>     name  language\n#> 1    Ven bulgarian\n#> 2  Gidon    german\n#> 3 Chenyu   chinese\n```\n:::\n\n\n\nIf we were to use our if/else-based greeting function to greet each user, everything works as we would expect:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npurrr::pwalk(users, greeting)\n#> Здравей Ven! Какъв страхотен ден! \n#> Hallo Gidon! Was für ein toller Tag! \n#> 嗨 Chenyu! 多么美好的一天\n```\n:::\n\n\n\nWhat about the greeting2, which uses `switch` to determine which greeting to use?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npurrr::pwalk(users, greeting2)\n#> 嗨 Ven! 多么美好的一天\n#> Здравей Gidon! Какъв страхотен ден!\n#> Hallo Chenyu! Was für ein toller Tag!\n```\n:::\n\n\n\nWhat the hell? Well, I cheated a bit and hid the warning R helpfully gave us (naughty!). Here is the output again without suppressing the warning:\n\n\n\n::: {.cell}\n\n```{.r .cell-code .code-overflow-wrap}\npurrr::pwalk(users, greeting2)\n#> Warning in switch(language, chinese = paste0(\"嗨 \", name, \"! 多么美好的一天\"), : EXPR is a \"factor\", treated as integer.\n#>  Consider using 'switch(as.character( * ), ...)' instead.\n#> 嗨 Ven! 多么美好的一天\n#> Warning in switch(language, chinese = paste0(\"嗨 \", name, \"! 多么美好的一天\"), : EXPR is a \"factor\", treated as integer.\n#>  Consider using 'switch(as.character( * ), ...)' instead.\n#> Здравей Gidon! Какъв страхотен ден!\n#> Warning in switch(language, chinese = paste0(\"嗨 \", name, \"! 多么美好的一天\"), : EXPR is a \"factor\", treated as integer.\n#>  Consider using 'switch(as.character( * ), ...)' instead.\n#> Hallo Chenyu! Was für ein toller Tag!\n```\n:::\n\n\n\nAh, that explains it (although doesn't excuse it). When a factor variable is passed to a switch statement, the variable is treated as an integer. By default factor levels are ordered alphabetically, which we can see if we examine our `language` factor structure:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nusers$language\n#> [1] bulgarian german    chinese  \n#> Levels: bulgarian chinese german\nstr(users$language)\n#>  Factor w/ 3 levels \"bulgarian\",\"chinese\",..: 1 3 2\n```\n:::\n\n\n\nSo Gidon get's greeted in Bulgarian, because his \"german\" language is coded as 3 in the factor variable, and the third check in `switch` corresponds to \"bulgarian\". The documentation (`?switch`) helpfully explains that\n\n> `switch` works in two distinct ways depending whether the first argument evaluates to a character string or a number.\n>\n> If the value of `EXPR` is not a character string it is coerced to integer. Note that this also happens for [`factor`](vscode-webview://1j32ru5leek8sf3kqosuqvfte16jrk6ppg82mr9lgucrkob51ojg/base/help/factor \"../../base/help/factor\")s, with a warning, as typically the character level is meant. If the integer is between 1 and `nargs()-1` then the corresponding element of `...` is evaluated and the result returned: thus if the first argument is `3` then the fourth argument is evaluated and returned.\n>\n> If `EXPR` evaluates to a character string then that string is matched (exactly) to the names of the elements in `...`...\n\nWow, ok, I never knew this, or if I did I have completely forgotten about it.\n\n## So what, we do get a warning don't we?\n\nWe sure do, but warnings can be suppressed, just like I did above. It's common to suppress output of functions when running many iterations of a chatty function in an analysis script and problems can easily go unnoticed. That's exactly what happened recently in our Bayesian measurement modeling R package when a user reported [a weird bug](https://github.com/venpopov/bmm/issues/269). We have one computational model that can apply different forms of Luce's choice decision rule - a standard version and a version passed through a softmax normalization. Due to this weird way that `switch` treats factors, the wrong normalization was applied. This is a recent and not yet officially released model, so we are yet to write all input validations. This could have easily go unnoticed and lead to incorrect model specification that nevertheless lets the model run.\n\n*Warnings are not a reliable way to signal undesired behavior*. Especially when the documentation of switch's warning itself notes that \"typically the character level is meant\". Well, if typically a character level is meant, why is the default EXACTLY THE OPPOSITE?!?\n\n## Fine, but you tell users \"language\" should be a character... right?\n\nWe do, but here's the kicker - R *loves* to turn character vector into factors. So much so that disabling such behavior was one of the main motivation behind the development of `tibbles.` Until R4.0.0, whenever you used a function like `read.csv()` to read a file as a data.frame, R by default [converted character columns to factors](https://blog.r-project.org/2020/02/16/stringsasfactors/). Thankfully now this default has been reversed, but here's the deal - NOT EVERYWHERE!\n\nOne place which I never knew R created factors out of character vectors is `expand.grid`. Expand.grid is a commonly used function to get a data.frame with all combinations of several variables, which is useful for running models with orthogonality manipulated conditions. E.g.:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconditions <- expand.grid(\n  value = c(1, 100),\n  version = c(\"cs\",\"ss\"), \n  choice_rule = c(\"simple\", \"softmax\")\n)\nconditions\n#>   value version choice_rule\n#> 1     1      cs      simple\n#> 2   100      cs      simple\n#> 3     1      ss      simple\n#> 4   100      ss      simple\n#> 5     1      cs     softmax\n#> 6   100      cs     softmax\n#> 7     1      ss     softmax\n#> 8   100      ss     softmax\n```\n:::\n\n\n\nCan you tell that version and choice_rule are factors? I've used `expand.grid` for years without knowing that behavior default of expand.grid, and it's partly that standard data.frame print method does not differentiate character and factor columns in any way. You can see that indeed we have factors underneath by using `str` for more details:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(conditions, give.attr = FALSE)\n#> 'data.frame':\t8 obs. of  3 variables:\n#>  $ value      : num  1 100 1 100 1 100 1 100\n#>  $ version    : Factor w/ 2 levels \"cs\",\"ss\": 1 1 2 2 1 1 2 2\n#>  $ choice_rule: Factor w/ 2 levels \"simple\",\"softmax\": 1 1 1 1 2 2 2 2\n```\n:::\n\n\n\nYou can examine the documentation, or directly check with `formals` that expand.grid, just like `read.csv` has a argument `stringsAsFactors`, which defaults to TRUE:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nformals(expand.grid)\n#> $...\n#> \n#> \n#> $KEEP.OUT.ATTRS\n#> [1] TRUE\n#> \n#> $stringsAsFactors\n#> [1] TRUE\n```\n:::\n\n\n\nWait, but didn't I just write that R4.0.0 solves the problem? As of R4.4.2, it only does that for `read.table` and `data.frame`, but not `expand.grid`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nversion$version.string\n#> [1] \"R version 4.4.2 (2024-10-31)\"\nformals(read.table)[\"stringsAsFactors\"]\n#> $stringsAsFactors\n#> [1] FALSE\nformals(data.frame)[\"stringsAsFactors\"]\n#> $stringsAsFactors\n#> [1] FALSE\nformals(expand.grid)[\"stringsAsFactors\"]\n#> $stringsAsFactors\n#> [1] TRUE\n```\n:::\n\n\n\nYou can of course change that by being explicit about not wanting factors, or use `tidyr::expand_grid` alternative instead:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexpand.grid(\n  value = c(1, 100),\n  version = c(\"cs\",\"ss\"), \n  choice_rule = c(\"simple\", \"softmax\"),\n  stringsAsFactors = FALSE\n) |> str(give.attr = FALSE)\n#> 'data.frame':\t8 obs. of  3 variables:\n#>  $ value      : num  1 100 1 100 1 100 1 100\n#>  $ version    : chr  \"cs\" \"cs\" \"ss\" \"ss\" ...\n#>  $ choice_rule: chr  \"simple\" \"simple\" \"simple\" \"simple\" ...\n\ntidyr::expand_grid(\n  value = c(1, 100),\n  version = c(\"cs\",\"ss\"), \n  choice_rule = c(\"simple\", \"softmax\")\n) |> str()\n#> tibble [8 × 3] (S3: tbl_df/tbl/data.frame)\n#>  $ value      : num [1:8] 1 1 1 1 100 100 100 100\n#>  $ version    : chr [1:8] \"cs\" \"cs\" \"ss\" \"ss\" ...\n#>  $ choice_rule: chr [1:8] \"simple\" \"softmax\" \"simple\" \"softmax\" ...\n```\n:::\n\n\n\nI am often annoyed at how frequently `tidyverse` packages break my code, and how often I have to relearn how to do things due to their fast pace of changes. I also dislike how interdependent and \"heavy\" tidyverse packages become - while I use them when writing analysis code, it is difficult to justify using them when writing packages that I wish to be lightweight and stable without constant watch. I also often get annoyed that tidyverse packages seem to often just wrap basic R functions because, which makes the language more varied than it needs to be. There are many arguments both pro and against the way that the `tidyverse` has affected the R community (some polemic discussion - e.g. [here](https://github.com/matloff/TidyverseSkeptic), [here](https://www.tinyverse.org/), [here](https://www.reddit.com/r/rprogramming/comments/rd4ksl/i_am_concerned_about_the_tidyverse_and_its_impact/), [here](https://forum.posit.co/t/should-tidyeval-be-abandoned/2238/12), [here](https://blog.thecoatlessprofessor.com/programming/r/woes-of-the-rlang-enabled-tidyverse/index.html)). I personally have shifted from a huge fan to a skeptic and nowadays try to do without when I can. But I don't want to throw away the baby with the bathwater. The tidyverse is right in at least one way - function APIs should be consistent and avoid \"magic\" behavior. Base R still suffers from that, mostly due to it being and very old language (or wanting to keep compatibility with an old language such as S).\n\n## What now?\n\nFirst, of course, is to sit down and do the annoying grunt work of going through all user-facing functions and ensuring that we test and validate every input. There's a ton of ways to do it, either with vanilla R and custom functions, or with the help of some validation packages I listed earlier. Then add more unit tests about edge cases to make sure things like this don't happen. And so on... We have done this for a lot of our existing code, but as this example taught me, it's easy to forget - and sometimes easy to not know.\n\nLong-term, however, I'm becoming more and more interested in programming languages that use a strong static type system. I've long taught that static typing is simply annoying - as a [self-taught](../../2024/reproducibility-is-hard) programmer, I haven't had the benefit of learning things \"the right way\". Over the last few months I've started digging deeper into programming as a core skill, exploring various languages and resources. I'm growing more and more attuned to the virtues of good type systems, for many other reasons. I'm sure another post on this topic is incoming at some time. In the meantime, follow this directive:\n\n``` r\nif (language == \"R\") {\n  stopifnot(inputs_are_carefully_validated())\n}\n```\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}